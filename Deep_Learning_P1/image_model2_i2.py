# -*- coding: utf-8 -*-
"""Image_model2_i2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EsGZeDsJv9dzMacWHdXJxc8YqKKZELjd
"""

#Mount the google drive
from google.colab import drive
drive.mount('/content/Drive')

from tensorflow.python.client import device_lib
device_lib.list_local_devices()

import pandas as pd

import os

# Create a list of file paths to your images
image_paths = [os.path.join("/content/Drive/MyDrive/cocodatasetsmall", filename) for filename in os.listdir("/content/Drive/MyDrive/cocodatasetsmall")]

# Create a DataFrame
df1 = pd.DataFrame({"Image_Path": image_paths})

from PIL import Image

df1.head()

df1['Image'] = df1['Image_Path'].apply(lambda path: Image.open(path))

df1['Image_Path'].head(100)

df=df1.head(5000)

target_size = (200, 200)

from PIL import Image
for index,imagerow in df.iterrows():
     image=imagerow[1]
     resized_image=image.resize(target_size)
     df.at[index, 'Image'] = resized_image

df_grayscale = df.copy()

for index,imagerow in df_grayscale.iterrows():
     image=imagerow[1]
     converted_image=image.convert('L')

print(df_grayscale.columns)
df_grayscale['GrayScale'] = None

for index,imagerow in df_grayscale.iterrows():
     image=imagerow[1]
     converted_image=image.convert('L')
     df_grayscale.at[index, 'GrayScale'] = converted_image

# Assuming you have a DataFrame named 'df' with a 'Loaded_Image' column containing Pillow Image objects
for index, row in df_grayscale.iterrows():
   if index<5:
    image = row['Image']
    display(image)
    converted_image = row['GrayScale']
    display(converted_image)

from sklearn.model_selection import train_test_split

X = df_grayscale['GrayScale']
Y = df_grayscale['Image']
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.01, random_state=42)

from keras.optimizers import Adam
import os
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
import tensorflow as tf
from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Input, Concatenate
from tensorflow.keras.models import Model

inputs = Input(shape=(200, 200,1))

    # Encoder
conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)
conv1 = Conv2D(64, 3, activation='relu', padding='same')(conv1)
pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)

conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)
conv2 = Conv2D(128, 3, activation='relu', padding='same')(conv2)
pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)

    # Middle
convm = Conv2D(256, 3, activation='relu', padding='same')(pool2)
convm = Conv2D(256, 3, activation='relu', padding='same')(convm)

    # Decoder
up1 = Concatenate()([UpSampling2D(size=(2, 2))(convm), conv2])
conv3 = Conv2D(128, 3, activation='relu', padding='same')(up1)
conv3 = Conv2D(128, 3, activation='relu', padding='same')(conv3)

up2 = Concatenate()([UpSampling2D(size=(2, 2))(conv3), conv1])
conv4 = Conv2D(64, 3, activation='relu', padding='same')(up2)
conv4 = Conv2D(64, 3, activation='relu', padding='same')(conv4)

outputs = Conv2D(3, 1, activation='sigmoid')(conv4)  # Output 3 channels for RGB

Model_Colourization = Model(inputs=inputs, outputs=outputs)

# from keras.models import Model
# Model_Colourization = Model(inputs=in_, outputs=model_)

LEARNING_RATE = 0.01
Model_Colourization.compile(optimizer=Adam(lr=LEARNING_RATE),
                            loss='mean_squared_error')
Model_Colourization.summary()

import numpy as np
grayscale_images = []
for image in X_train:
    grayscale_array = np.array(image)
    grayscale_images.append(grayscale_array)

color_images = []
for image in Y_train:
    Color_array = np.array(image)
    color_images.append(Color_array)

# Convert grayscale images to TensorFlow tensors
grayscale_tensors = [tf.convert_to_tensor(image, dtype=tf.float32) for image in grayscale_images]

# Convert color images to TensorFlow tensors
color_tensors = [tf.convert_to_tensor(image, dtype=tf.float32) for image in color_images]

indices = []
for i, tensor in enumerate(color_tensors):
    if tensor.shape != (200, 200, 3):
        indices.append(i)

clean_gray_tensors=[]
for i, tensors in enumerate(grayscale_tensors):
    if i not in indices:
        clean_gray_tensors.append(tensors)

clean_color_tensors=[]
for i, tensors in enumerate(color_tensors):
    if i not in indices:
        clean_color_tensors.append(tensors)

reshaped_gray_tensors= tf.reshape(clean_gray_tensors,(-1,200,200,1))

reshaped_color_tensors= tf.reshape(clean_color_tensors,(-1,200,200,3))

# Assuming your tensors are numpy arrays
gray_tensors = np.array(reshaped_gray_tensors)
color_tensors = np.array(reshaped_color_tensors)

# Normalize grayscale tensors
normalized_gray_tensors = gray_tensors / 255.0

# Normalize color tensors
normalized_color_tensors = color_tensors / 255.0

print(normalized_gray_tensors.shape)
print(normalized_color_tensors.shape)

tf.keras.backend.clear_session()

X_train, X_val, y_train, y_val= train_test_split(normalized_gray_tensors, normalized_color_tensors, test_size=0.2, random_state=42)

from tensorflow.keras.utils import Sequence
import numpy as np

class DataGenerator(Sequence):
    def __init__(self, x_set, y_set, batch_size):
        self.x, self.y = x_set, y_set
        self.batch_size = batch_size

    def __len__(self):
        return int(np.ceil(len(self.x) / float(self.batch_size)))

    def __getitem__(self, idx):
        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]
        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]
        return batch_x, batch_y

train_gen = DataGenerator(X_train, y_train, 16)
test_gen = DataGenerator(X_val, y_val, 16)

train_gen

test_gen

history = Model_Colourization.fit(train_gen,
                    epochs=20,validation_data=test_gen
                  )

# history=Model_Colourization.fit(X_train, y_train,epochs=20,verbose=1,steps_per_epoch=10,shuffle=True,batch_size=16)

print(history.history.keys())

import matplotlib.pyplot as plt
# Access training history
train_loss = history.history['loss']
val_loss = history.history['val_loss']


# Print or visualize the training and validation loss along with accuracy over epochs
epochs = range(1, len(train_loss) + 1)


# Plotting loss
plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(epochs, train_loss, 'bo', label='Training Loss')
plt.plot(epochs, val_loss, 'r', label='Validation Loss')  # Add this line for validation loss
plt.title('Training and Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

# Show the plot
plt.show()

import numpy as np
test_images = []
for image in X_test:
    test_array = np.array(image)
    test_images.append(test_array)

test_tensors = [tf.convert_to_tensor(image, dtype=tf.float32) for image in test_images]

reshaped_test_tensors= tf.reshape(test_tensors,(-1,200,200,1))

normalized_test_tensors = np.array(reshaped_test_tensors) / 255.0

Predicted_color_images=Model_Colourization.predict(normalized_test_tensors)

image_data = (Predicted_color_images[1] * 255).astype('uint8')
display(image_data)

import numpy as np
import matplotlib.pyplot as plt
# Display the image
plt.imshow(image_data)
plt.axis('off')  # Optional: Turn off axis labels
plt.show()

#Create a NumPy ndarray with shape (200, 200, 3) for demonstration (replace this with your own ndarray)
image_data = Y_test.iloc[1]  # Replace with your actual image data

# Display the image
plt.imshow(image_data)
plt.axis('off')  # Optional: Turn off axis labels
plt.show()

#Create a NumPy ndarray with shape (200, 200, 3) for demonstration (replace this with your own ndarray)
image_data = X_test.iloc[1]  # Replace with your actual image data

# Display the image
plt.imshow(image_data,cmap='gray')
plt.axis('off')  # Optional: Turn off axis labels
plt.show()

from sklearn.metrics import mean_squared_error
import numpy as np

# Assuming Y_test is a DataFrame with a single 'image' column
# Make sure the shapes of the images are the same

# Initialize an empty list to store individual MSE values
mse_values = []

# Calculate MSE for each pair of images
for i in range(len(Y_test)):
    # Convert the PIL image to a NumPy array
    y_true = np.array(Y_test.iloc[i]).astype('uint8')/255

    # Get the predicted image from the list or array
    y_pred = (Predicted_color_images[i] )  # Scale predicted image by 255

    # # Flatten the arrays if needed (assuming images are 2D)
    y_true_flat = y_true.ravel()
    y_pred_flat = y_pred.ravel()

    if y_true.shape != y_pred.shape:
        print(f"Shapes are inconsistent for images {i}. Skipping...")
        continue

    # # Calculate MSE for the pair
    mse = mean_squared_error(y_true_flat, y_pred_flat)
    mse_values.append(mse)

# Calculate the mean MSE across all pairs
average_mse = np.mean(mse_values)

print(f"Average MSE across {len(Y_test)} images: {average_mse}")

y_true = np.array(Y_test.iloc[i]).astype('uint8')

y_true

y_true_flat

