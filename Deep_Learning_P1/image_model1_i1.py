# -*- coding: utf-8 -*-
"""Image_Model1_I1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1c4q1qDQBrynW7TKCaDfUiGuVcag3JpYr
"""

#Mount the google drive
from google.colab import drive
drive.mount('/content/Drive')

from tensorflow.python.client import device_lib
device_lib.list_local_devices()

import pandas as pd

import os

# Create a list of file paths to your images
image_paths = [os.path.join("/content/Drive/MyDrive/cocodatasetsmall", filename) for filename in os.listdir("/content/Drive/MyDrive/cocodatasetsmall")]

# Create a DataFrame
df1 = pd.DataFrame({"Image_Path": image_paths})

from PIL import Image

df1.head()

df1['Image'] = df1['Image_Path'].apply(lambda path: Image.open(path))

df1['Image_Path'].head(100)

df=df1.head(5000)

target_size = (200, 200)

from PIL import Image
for index,imagerow in df.iterrows():
     image=imagerow[1]
     resized_image=image.resize(target_size)
     df.at[index, 'Image'] = resized_image

df_grayscale = df.copy()

for index,imagerow in df_grayscale.iterrows():
     image=imagerow[1]
     converted_image=image.convert('L')

print(df_grayscale.columns)
df_grayscale['GrayScale'] = None

for index,imagerow in df_grayscale.iterrows():
     image=imagerow[1]
     converted_image=image.convert('L')
     df_grayscale.at[index, 'GrayScale'] = converted_image

# Assuming you have a DataFrame named 'df' with a 'Loaded_Image' column containing Pillow Image objects
for index, row in df_grayscale.iterrows():
   if index>6 and index<11:
    image = row['Image']
    display(image)
    converted_image = row['GrayScale']
    display(converted_image)

from sklearn.model_selection import train_test_split

X = df_grayscale['GrayScale']
Y = df_grayscale['Image']
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.01, random_state=42)

len(X_test)

import tensorflow as tf
from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D,Input,LeakyReLU,BatchNormalization
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import concatenate
from keras.optimizers import Adam
import tensorflow.keras.utils
from tensorflow import keras


in_ = Input(shape=(200, 200,1))


model_ = Conv2D(16,(3,3),padding='same',strides=1)(in_)
model_ = LeakyReLU()(model_)
    #model_ = Conv2D(64,(3,3), activation='relu',strides=1)(model_)
model_ = Conv2D(32,(3,3),padding='same',strides=1)(model_)
model_ = LeakyReLU()(model_)
model_ = BatchNormalization()(model_)
model_ = MaxPooling2D(pool_size=(2,2),padding='same')(model_)

model_ = Conv2D(64,(3,3),padding='same',strides=1)(model_)
model_ = LeakyReLU()(model_)
model_ = BatchNormalization()(model_)
model_ = MaxPooling2D(pool_size=(2,2),padding='same')(model_)

model_ = Conv2D(128,(3,3),padding='same',strides=1)(model_)
model_ = LeakyReLU()(model_)
model_ = BatchNormalization()(model_)

model_ = Conv2D(256,(3,3),padding='same',strides=1)(model_)
model_ = LeakyReLU()(model_)
model_ = BatchNormalization()(model_)

model_ = UpSampling2D((2, 2))(model_)
model_ = Conv2D(128,(3,3),padding='same',strides=1)(model_)
model_ = LeakyReLU()(model_)
model_ = BatchNormalization()(model_)

model_ = UpSampling2D((2, 2))(model_)
model_ = Conv2D(64,(3,3), padding='same',strides=1)(model_)
model_ = LeakyReLU()(model_)
    #model_ = BatchNormalization()(model_)

concat_ = concatenate([model_, in_])

model_ = Conv2D(64,(3,3), padding='same',strides=1)(concat_)
model_ = LeakyReLU()(model_)
model_ = BatchNormalization()(model_)

model_ = Conv2D(32,(3,3),padding='same',strides=1)(model_)
model_ = LeakyReLU()(model_)
    #model_ = BatchNormalization()(model_)

model_ = Conv2D(3,(3,3), activation='tanh',padding='same',strides=1)(model_)

from keras.models import Model
Model_Colourization = Model(inputs=in_, outputs=model_)

LEARNING_RATE = 0.001
Model_Colourization.compile(optimizer=Adam(lr=LEARNING_RATE),
                            loss='mean_squared_error')
Model_Colourization.summary()

keras.utils.plot_model(Model_Colourization, "OutputModel.png", show_shapes = True)

import numpy as np
grayscale_images = []
for image in X_train:
    grayscale_array = np.array(image)
    grayscale_images.append(grayscale_array)

color_images = []
for image in Y_train:
    Color_array = np.array(image)
    color_images.append(Color_array)

# Convert grayscale images to TensorFlow tensors
grayscale_tensors = [tf.convert_to_tensor(image, dtype=tf.float32) for image in grayscale_images]

# Convert color images to TensorFlow tensors
color_tensors = [tf.convert_to_tensor(image, dtype=tf.float32) for image in color_images]

indices = []
for i, tensor in enumerate(color_tensors):
    if tensor.shape != (200, 200, 3):
        indices.append(i)

clean_gray_tensors=[]
for i, tensors in enumerate(grayscale_tensors):
    if i not in indices:
        clean_gray_tensors.append(tensors)

clean_color_tensors=[]
for i, tensors in enumerate(color_tensors):
    if i not in indices:
        clean_color_tensors.append(tensors)

reshaped_gray_tensors= tf.reshape(clean_gray_tensors,(-1,200,200,1))

reshaped_color_tensors= tf.reshape(clean_color_tensors,(-1,200,200,3))

# Assuming your tensors are numpy arrays
gray_tensors = np.array(reshaped_gray_tensors)
color_tensors = np.array(reshaped_color_tensors)

# Normalize grayscale tensors
normalized_gray_tensors = gray_tensors / 255.0

# Normalize color tensors
normalized_color_tensors = color_tensors / 255.0

print(normalized_gray_tensors.shape)
print(normalized_color_tensors.shape)

tf.keras.backend.clear_session()

X_train, X_val, y_train, y_val= train_test_split(normalized_gray_tensors, normalized_color_tensors, test_size=0.2, random_state=42)

from tensorflow.keras.utils import Sequence
import numpy as np

class DataGenerator(Sequence):
    def __init__(self, x_set, y_set, batch_size):
        self.x, self.y = x_set, y_set
        self.batch_size = batch_size

    def __len__(self):
        return int(np.ceil(len(self.x) / float(self.batch_size)))

    def __getitem__(self, idx):
        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]
        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]
        return batch_x, batch_y

train_gen = DataGenerator(X_train, y_train, 16)
test_gen = DataGenerator(X_val, y_val, 16)

train_gen

test_gen

history = Model_Colourization.fit(train_gen,
                    epochs=10,validation_data=test_gen
                  )

# history=Model_Colourization.fit(X_train, y_train,epochs=20,verbose=1,steps_per_epoch=10,shuffle=True,batch_size=16)

print(history.history.keys())

import matplotlib.pyplot as plt
# Access training history
train_loss = history.history['loss']
val_loss = history.history['val_loss']


# Print or visualize the training and validation loss along with accuracy over epochs
epochs = range(1, len(train_loss) + 1)


# Plotting loss
plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(epochs, train_loss, 'bo', label='Training Loss')
plt.plot(epochs, val_loss, 'r', label='Validation Loss')  # Add this line for validation loss
plt.title('Training and Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

# Show the plot
plt.show()

import numpy as np
test_images = []
for image in X_test:
    test_array = np.array(image)
    test_images.append(test_array)

test_tensors = [tf.convert_to_tensor(image, dtype=tf.float32) for image in test_images]

reshaped_test_tensors= tf.reshape(test_tensors,(-1,200,200,1))

normalized_test_tensors = np.array(reshaped_test_tensors) / 255.0

Predicted_color_images=Model_Colourization.predict(normalized_test_tensors)

image_data = (Predicted_color_images[1] * 255).astype('uint8')
display(image_data)

import numpy as np
import matplotlib.pyplot as plt
# Display the image
plt.imshow(image_data)
plt.axis('off')  # Optional: Turn off axis labels
plt.show()

#Create a NumPy ndarray with shape (200, 200, 3) for demonstration (replace this with your own ndarray)
image_data = Y_test.iloc[1]  # Replace with your actual image data

# Display the image
plt.imshow(image_data)
plt.axis('off')  # Optional: Turn off axis labels
plt.show()

#Create a NumPy ndarray with shape (200, 200, 3) for demonstration (replace this with your own ndarray)
image_data = X_test.iloc[1]  # Replace with your actual image data

# Display the image
plt.imshow(image_data,cmap='gray')
plt.axis('off')  # Optional: Turn off axis labels
plt.show()

from sklearn.metrics import mean_squared_error
import numpy as np

# Assuming Y_test is a DataFrame with a single 'image' column
# Make sure the shapes of the images are the same

# Initialize an empty list to store individual MSE values
mse_values = []

# Calculate MSE for each pair of images
for i in range(len(Y_test)):
    # Convert the PIL image to a NumPy array
    y_true = np.array(Y_test.iloc[i]).astype('uint8')/255

    # Get the predicted image from the list or array
    y_pred = (Predicted_color_images[i] )  # Scale predicted image by 255

    # # Flatten the arrays if needed (assuming images are 2D)
    y_true_flat = y_true.ravel()
    y_pred_flat = y_pred.ravel()

    if y_true.shape != y_pred.shape:
        print(f"Shapes are inconsistent for images {i}. Skipping...")
        continue

    # # Calculate MSE for the pair
    mse = mean_squared_error(y_true_flat, y_pred_flat)
    mse_values.append(mse)

# Calculate the mean MSE across all pairs
average_mse = np.mean(mse_values)

print(f"Average MSE across test images: {average_mse}")

